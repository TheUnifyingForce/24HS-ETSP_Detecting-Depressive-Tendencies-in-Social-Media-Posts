{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EkugXyMh3T9W",
    "outputId": "0cb25cfa-49ef-4bb2-b0e8-1c2ad227487a"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Load data\n",
    "train_df = pd.read_csv('train.csv')\n",
    "val_df = pd.read_csv('dev.csv')\n",
    "test_df = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>missed brent praise band fun lead guitarist lt...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tanialt beth tastic widgetsworld spcialndsjung...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>m m feel like ending just want girlfriend reje...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>late night snack glass oj b c m quot sickness ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ensconced thought diametrically opposed gradua...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  missed brent praise band fun lead guitarist lt...      0\n",
       "1  tanialt beth tastic widgetsworld spcialndsjung...      1\n",
       "2  m m feel like ending just want girlfriend reje...      1\n",
       "3  late night snack glass oj b c m quot sickness ...      0\n",
       "4  ensconced thought diametrically opposed gradua...      1"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pbzO1zgq-Azu"
   },
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "QqA54PT8-ACH"
   },
   "outputs": [],
   "source": [
    "# pip install transformers datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "StUkbcdY959y"
   },
   "outputs": [],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification, TrainingArguments, Trainer\n",
    "from transformers import DataCollatorWithPadding\n",
    "import torch\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"TRANSFORMERS_VERBOSITY\"] = \"error\"\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9PBpKmf19fBK"
   },
   "source": [
    "### cardiffnlp/twitter-roberta-base-sentiment\n",
    "https://huggingface.co/cardiffnlp/twitter-roberta-base-sentiment?text=I+like+you.+I+love+you\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert DataFrame to Hugging Face Datasets\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "val_dataset = Dataset.from_pandas(val_df)\n",
    "test_dataset = Dataset.from_pandas(test_df)\n",
    "\n",
    "# Merge datasets\n",
    "dataset = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'validation': val_dataset,\n",
    "    'test': test_dataset\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /cardiffnlp/twitter-roberta-base-sentiment/resolve/main/vocab.json HTTP/1.1\" 200 0\n",
      "loading file vocab.json from cache at /Users/qiguo/.cache/huggingface/hub/models--cardiffnlp--twitter-roberta-base-sentiment/snapshots/daefdd1f6ae931839bce4d0f3db0a1a4265cd50f/vocab.json\n",
      "loading file merges.txt from cache at /Users/qiguo/.cache/huggingface/hub/models--cardiffnlp--twitter-roberta-base-sentiment/snapshots/daefdd1f6ae931839bce4d0f3db0a1a4265cd50f/merges.txt\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at /Users/qiguo/.cache/huggingface/hub/models--cardiffnlp--twitter-roberta-base-sentiment/snapshots/daefdd1f6ae931839bce4d0f3db0a1a4265cd50f/special_tokens_map.json\n",
      "loading file tokenizer_config.json from cache at None\n",
      "loading configuration file config.json from cache at /Users/qiguo/.cache/huggingface/hub/models--cardiffnlp--twitter-roberta-base-sentiment/snapshots/daefdd1f6ae931839bce4d0f3db0a1a4265cd50f/config.json\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"cardiffnlp/twitter-roberta-base-sentiment\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.23.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7341a1b776e14dce978c25cce5b0cb1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a61f405132543e8a815a5fdcf59eebe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8b5dca73ea44db59196fd90b52c9a33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tokenizer\n",
    "model_checkpoint = \"cardiffnlp/twitter-roberta-base-sentiment\"\n",
    "tokenizer = RobertaTokenizer.from_pretrained(model_checkpoint)\n",
    "\n",
    "# Tokenize\n",
    "def preprocess_function(examples):\n",
    "    cleaned_texts = [str(text) if text else \"\" for text in examples[\"text\"]]\n",
    "    return tokenizer(cleaned_texts, truncation=True, max_length=128)\n",
    "\n",
    "tokenized_datasets = dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /cardiffnlp/twitter-roberta-base-sentiment/resolve/main/config.json HTTP/1.1\" 200 0\n",
      "loading configuration file config.json from cache at /Users/qiguo/.cache/huggingface/hub/models--cardiffnlp--twitter-roberta-base-sentiment/snapshots/daefdd1f6ae931839bce4d0f3db0a1a4265cd50f/config.json\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"tweeteval_new/roberta-base-rt-sentiment/\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.23.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at /Users/qiguo/.cache/huggingface/hub/models--cardiffnlp--twitter-roberta-base-sentiment/snapshots/daefdd1f6ae931839bce4d0f3db0a1a4265cd50f/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n",
      "\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n",
      "- classifier.out_proj.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load the model\n",
    "model = RobertaForSequenceClassification.from_pretrained(model_checkpoint, num_labels=2, ignore_mismatched_sizes=True)  # 2 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Collector\n",
    "data_collator = DataCollatorWithPadding(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    preds = torch.argmax(torch.tensor(predictions), dim=-1)\n",
    "    accuracy = (preds == torch.tensor(labels)).float().mean().item()\n",
    "    return {\"accuracy\": accuracy}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    }
   ],
   "source": [
    "# parameters\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning rate scheduler\n",
    "num_training_steps = len(tokenized_datasets[\"train\"]) // training_args.per_device_train_batch_size * training_args.num_train_epochs\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
    "                                            num_warmup_steps=0,\n",
    "                                            num_training_steps=num_training_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running training *****\n",
      "  Num examples = 6184\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1935\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1935' max='1935' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1935/1935 59:34, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.179600</td>\n",
       "      <td>0.121862</td>\n",
       "      <td>0.963777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.064800</td>\n",
       "      <td>0.128373</td>\n",
       "      <td>0.974127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.024000</td>\n",
       "      <td>0.125911</td>\n",
       "      <td>0.976714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.144965</td>\n",
       "      <td>0.975420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.142296</td>\n",
       "      <td>0.974127</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 773\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./results/checkpoint-500\n",
      "Configuration saved in ./results/checkpoint-500/config.json\n",
      "Model weights saved in ./results/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-500/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 773\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./results/checkpoint-1000\n",
      "Configuration saved in ./results/checkpoint-1000/config.json\n",
      "Model weights saved in ./results/checkpoint-1000/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-1000/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-1000/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 773\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./results/checkpoint-1500\n",
      "Configuration saved in ./results/checkpoint-1500/config.json\n",
      "Model weights saved in ./results/checkpoint-1500/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-1500/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-1500/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 773\n",
      "  Batch size = 16\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 773\n",
      "  Batch size = 16\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1935, training_loss=0.05066942368262238, metrics={'train_runtime': 3576.6611, 'train_samples_per_second': 8.645, 'train_steps_per_second': 0.541, 'total_flos': 1841991165252480.0, 'train_loss': 0.05066942368262238, 'epoch': 5.0})"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Trainer class\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    optimizers=(optimizer, scheduler),\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# Train\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 445,
     "referenced_widgets": [
      "6da44f13a284451ca8c4bf68c3d8b421",
      "f92da9b60b0b495f8b937c9bda1c7f6a",
      "689163b20cda4097ace66a99862d6c61",
      "fabf53cd91ca4a1e89567bf7c6d47c49",
      "8d3f09e85c57469fbbe12a566097431b",
      "85fbfe4074c1472ea5d67c9cffabb38c",
      "da47dee2ce5d47c99e5b55d2e61be352",
      "947d37a10f674733897f7c062feff1e6",
      "799015bd31c8441f9de61f77bd381563",
      "4c8fdd7ab5e5412989b1eebed2cb0f32",
      "18ef0f43fc8c407db9e93fc2eb456f09",
      "02e5c984c09f435a8c9ad7fee9c0a3b6",
      "5e5b1574b89f4266bf5069a75bfd1259",
      "6b969a0ec21d44afbb294752e0829879",
      "5e79822663234199bbe63f1bb3b07739",
      "27888e6192c74a13b51525f5b069246c",
      "2f0301ad571c43f4a3f6c74ee11478ae",
      "920685d2c4524821aa53546cb15ca4cc",
      "49adb58f54964934ab25de27be100fb2",
      "c248980abfef4874ab0003a5c5fe767d",
      "1fac47e82d8445fe9c061c5c817b7c07",
      "8aed4c454d1f4264aaabaa1d9df58012",
      "87ee335a83a24c3d9df0668f5590f94b",
      "c4679acd51ed487db62902f93b68597d",
      "f38daed0ecee4e5f93f95435feca0992",
      "4184657ba94e4390a12546a75189b23c",
      "abd7f1c0737247e48a2862bbbee86b74",
      "d764d603b0704c9890291f2e2db0e76a",
      "570858b160114bd7989322f8171be5f5",
      "43d38d94d64843c2822fcb105c44b9ff",
      "8266a18427f249d4b25c6ac3ff87f33b",
      "8f0d6b2d68e24d4f92eecdf40266dbb5",
      "1d5cf447c04047a5b763e2258918a5a3"
     ]
    },
    "id": "jajk_CcC5Mnj",
    "outputId": "476ab49d-44c4-454d-8e76-af2548505ece"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 773\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation metrics:\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 774\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test metrics:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.1634438931941986,\n",
       " 'eval_accuracy': 0.9741601943969727,\n",
       " 'eval_runtime': 24.3621,\n",
       " 'eval_samples_per_second': 31.771,\n",
       " 'eval_steps_per_second': 2.011,\n",
       " 'epoch': 5.0}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate\n",
    "print(\"Validation metrics:\")\n",
    "trainer.evaluate(eval_dataset=tokenized_datasets[\"validation\"])\n",
    "\n",
    "print(\"Test metrics:\")\n",
    "trainer.evaluate(eval_dataset=tokenized_datasets[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ./trained_model/config.json\n",
      "Model weights saved in ./trained_model/pytorch_model.bin\n",
      "tokenizer config file saved in ./trained_model/tokenizer_config.json\n",
      "Special tokens file saved in ./trained_model/special_tokens_map.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('./trained_model/tokenizer_config.json',\n",
       " './trained_model/special_tokens_map.json',\n",
       " './trained_model/vocab.json',\n",
       " './trained_model/merges.txt',\n",
       " './trained_model/added_tokens.json')"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save\n",
    "model.save_pretrained('./trained_model')\n",
    "tokenizer.save_pretrained('./trained_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load\n",
    "# model = RobertaForSequenceClassification.from_pretrained('./trained_model')\n",
    "# tokenizer = RobertaTokenizer.from_pretrained('./trained_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions for the test set using the trained model\n",
    "def get_predictions_and_logits(trainer, dataset):\n",
    "    predictions, labels, metrics = trainer.predict(dataset)\n",
    "    \n",
    "    # Convert logits to predicted labels (0 or 1)\n",
    "    predicted_labels = np.argmax(predictions, axis=-1)\n",
    "\n",
    "    return predictions, predicted_labels, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 774\n",
      "  Batch size = 16\n"
     ]
    }
   ],
   "source": [
    "# Get predictions, logits, and true labels for the test dataset\n",
    "predictions, predicted_labels, true_labels = get_predictions_and_logits(trainer, tokenized_datasets[\"test\"])\n",
    "\n",
    "# Convert logits to pandas DataFrame for easy manipulation\n",
    "logits_df = pd.DataFrame(predictions, columns=[\"logit_\" + str(i) for i in range(predictions.shape[1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved\n"
     ]
    }
   ],
   "source": [
    "# Create a DataFrame with text, true labels, and predicted labels\n",
    "results_df = pd.DataFrame({\n",
    "    'text': tokenized_datasets[\"test\"][\"text\"],\n",
    "    'label': true_labels,\n",
    "    'label_pred': predicted_labels\n",
    "})\n",
    "\n",
    "# Concatenate logits DataFrame with the results_df\n",
    "final_df = pd.concat([results_df, logits_df], axis=1)\n",
    "final_df.to_csv(\"test_predictions_with_logits_Train.csv\", index=False)\n",
    "\n",
    "print(\"Results saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out misclassified samples\n",
    "misclassified_df = results_df[results_df['label'] != results_df['label_pred']]\n",
    "misclassified_df.to_csv('misclassified_samples_Train.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassification distribution:\n",
      "label\n",
      "0    10\n",
      "1    10\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Count per label\n",
    "misclassified_counts = misclassified_df['label'].value_counts()\n",
    "\n",
    "# Display distribution\n",
    "print(f\"Misclassification distribution:\\n{misclassified_counts}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>label_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>stress culminates physical pain</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>smoked time month m freaking idk edit m good b...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>fuck la circulation ce mat</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>profile want read</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>stupid arranged marriage ll convert marry love</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>confused don t know whats real m dramatic actu...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>hate life today s s post</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>body reply</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>just did km tready want die m built running</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>penalba por favor decime ke estas involucrado ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>wtf doing</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>m gon na time just got ta graduate stupid degree</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>t decide really want</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>hardest thing schedule chat end day usually</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>just let everquest subscription lapse just don...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538</th>\n",
       "      <td>hhh s time like want thing stay right come wreck</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>641</th>\n",
       "      <td>thought wa interesting way look wanted share</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>hello just need music listen spend time thank</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760</th>\n",
       "      <td>m kind sad bullshit</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  label  label_pred\n",
       "36                     stress culminates physical pain      0           1\n",
       "64   smoked time month m freaking idk edit m good b...      1           0\n",
       "72                          fuck la circulation ce mat      0           1\n",
       "77                                   profile want read      1           0\n",
       "80      stupid arranged marriage ll convert marry love      0           1\n",
       "90   confused don t know whats real m dramatic actu...      1           0\n",
       "109                           hate life today s s post      1           0\n",
       "205                                         body reply      0           1\n",
       "207        just did km tready want die m built running      0           1\n",
       "262  penalba por favor decime ke estas involucrado ...      0           1\n",
       "285                                          wtf doing      1           0\n",
       "322   m gon na time just got ta graduate stupid degree      1           0\n",
       "346                               t decide really want      1           0\n",
       "435        hardest thing schedule chat end day usually      0           1\n",
       "445                                               None      1           0\n",
       "504  just let everquest subscription lapse just don...      0           1\n",
       "538   hhh s time like want thing stay right come wreck      0           1\n",
       "641       thought wa interesting way look wanted share      1           0\n",
       "745      hello just need music listen spend time thank      1           0\n",
       "760                                m kind sad bullshit      0           1"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "misclassified_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VsNKMHdg9g3T"
   },
   "source": [
    "### nlptown/bert-base-multilingual-uncased-sentiment\n",
    "https://huggingface.co/nlptown/bert-base-multilingual-uncased-sentiment?text=i+am+so+sad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51ab5d541fd2471ba9dc3b7c94a813b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/872k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09714cc046314905b205a47831a4a120",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46e53cc89a444c908892c81690f5e53f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/39.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file vocab.txt from cache at /Users/qiguo/.cache/huggingface/hub/models--nlptown--bert-base-multilingual-uncased-sentiment/snapshots/edd66abe7147abbc7c23e0c339a5f617918d8060/vocab.txt\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at /Users/qiguo/.cache/huggingface/hub/models--nlptown--bert-base-multilingual-uncased-sentiment/snapshots/edd66abe7147abbc7c23e0c339a5f617918d8060/special_tokens_map.json\n",
      "loading file tokenizer_config.json from cache at /Users/qiguo/.cache/huggingface/hub/models--nlptown--bert-base-multilingual-uncased-sentiment/snapshots/edd66abe7147abbc7c23e0c339a5f617918d8060/tokenizer_config.json\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "590b541febb34147bfc6605164c266d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/953 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /Users/qiguo/.cache/huggingface/hub/models--nlptown--bert-base-multilingual-uncased-sentiment/snapshots/edd66abe7147abbc7c23e0c339a5f617918d8060/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"nlptown/bert-base-multilingual-uncased-sentiment\",\n",
      "  \"_num_labels\": 5,\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"finetuning_task\": \"sentiment-analysis\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"1 star\",\n",
      "    \"1\": \"2 stars\",\n",
      "    \"2\": \"3 stars\",\n",
      "    \"3\": \"4 stars\",\n",
      "    \"4\": \"5 stars\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"1 star\": 0,\n",
      "    \"2 stars\": 1,\n",
      "    \"3 stars\": 2,\n",
      "    \"4 stars\": 3,\n",
      "    \"5 stars\": 4\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.23.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 105879\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6abb78e7917f4be1aefd3a6c23199890",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae63bd434a3b4b7184b72e86ffb1ef0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9145ff3ca76647b68e5333ce7cb75912",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /Users/qiguo/.cache/huggingface/hub/models--nlptown--bert-base-multilingual-uncased-sentiment/snapshots/edd66abe7147abbc7c23e0c339a5f617918d8060/config.json\n",
      "Model config BertConfig {\n",
      "  \"_num_labels\": 5,\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"finetuning_task\": \"sentiment-analysis\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.23.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 105879\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4c0b618a177457eae2e82e94262f8f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/669M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading weights file pytorch_model.bin from cache at /Users/qiguo/.cache/huggingface/hub/models--nlptown--bert-base-multilingual-uncased-sentiment/snapshots/edd66abe7147abbc7c23e0c339a5f617918d8060/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at nlptown/bert-base-multilingual-uncased-sentiment and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([5, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([5]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running training *****\n",
      "  Num examples = 6184\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1935\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1935' max='1935' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1935/1935 1:02:34, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.206400</td>\n",
       "      <td>0.144901</td>\n",
       "      <td>0.953428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.037300</td>\n",
       "      <td>0.110792</td>\n",
       "      <td>0.971539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.044000</td>\n",
       "      <td>0.153201</td>\n",
       "      <td>0.970246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.185412</td>\n",
       "      <td>0.968952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.015800</td>\n",
       "      <td>0.189895</td>\n",
       "      <td>0.971539</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 773\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./results/checkpoint-500\n",
      "Configuration saved in ./results/checkpoint-500/config.json\n",
      "Model weights saved in ./results/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-500/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 773\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./results/checkpoint-1000\n",
      "Configuration saved in ./results/checkpoint-1000/config.json\n",
      "Model weights saved in ./results/checkpoint-1000/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-1000/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-1000/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 773\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./results/checkpoint-1500\n",
      "Configuration saved in ./results/checkpoint-1500/config.json\n",
      "Model weights saved in ./results/checkpoint-1500/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-1500/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-1500/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 773\n",
      "  Batch size = 16\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 773\n",
      "  Batch size = 16\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 773\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation metrics:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='49' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [49/49 00:49]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 774\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test metrics:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.1882229596376419,\n",
       " 'eval_accuracy': 0.9728682041168213,\n",
       " 'eval_runtime': 24.7361,\n",
       " 'eval_samples_per_second': 31.29,\n",
       " 'eval_steps_per_second': 1.981,\n",
       " 'epoch': 5.0}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert DataFrame to Hugging Face Datasets\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "val_dataset = Dataset.from_pandas(val_df)\n",
    "test_dataset = Dataset.from_pandas(test_df)\n",
    "\n",
    "# datasets\n",
    "dataset = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'validation': val_dataset,\n",
    "    'test': test_dataset\n",
    "})\n",
    "\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "\n",
    "# Load Tokenizer for BERT\n",
    "model_checkpoint = \"nlptown/bert-base-multilingual-uncased-sentiment\"  \n",
    "tokenizer = BertTokenizer.from_pretrained(model_checkpoint)  # Changed to BertTokenizer\n",
    "\n",
    "# Tokenize\n",
    "def preprocess_function(examples):\n",
    "    cleaned_texts = [str(text) if text else \"\" for text in examples[\"text\"]]\n",
    "    return tokenizer(cleaned_texts, truncation=True, max_length=128)\n",
    "\n",
    "tokenized_datasets = dataset.map(preprocess_function, batched=True)\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(model_checkpoint, num_labels=2, ignore_mismatched_sizes=True)  \n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer)\n",
    "\n",
    "# Evaluation function\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    preds = torch.argmax(torch.tensor(predictions), dim=-1)  \n",
    "    accuracy = (preds == torch.tensor(labels)).float().mean().item()  \n",
    "    return {\"accuracy\": accuracy}\n",
    "\n",
    "# Training parameters\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",  \n",
    "    learning_rate=2e-5,  \n",
    "    per_device_train_batch_size=16, \n",
    "    per_device_eval_batch_size=16,  \n",
    "    num_train_epochs=5, \n",
    "    weight_decay=0.01,  \n",
    "    logging_dir='./logs',  \n",
    "    logging_steps=10,  \n",
    ")\n",
    "\n",
    "# Optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-5)\n",
    "\n",
    "# Learning rate scheduler\n",
    "num_training_steps = len(tokenized_datasets[\"train\"]) // training_args.per_device_train_batch_size * training_args.num_train_epochs\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps=0, \n",
    "                                            num_training_steps=num_training_steps)\n",
    "\n",
    "# Trainer class\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    optimizers=(optimizer, scheduler),\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n",
    "\n",
    "# Evaluate on the validation dataset\n",
    "print(\"Validation metrics:\")\n",
    "trainer.evaluate(eval_dataset=tokenized_datasets[\"validation\"])\n",
    "\n",
    "# Evaluate on the test dataset\n",
    "print(\"Test metrics:\")\n",
    "trainer.evaluate(eval_dataset=tokenized_datasets[\"test\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test evaluation without training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Disable tokenizers parallelism\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "\n",
    "# Clear the Hugging Face cache\n",
    "# !rm -rf ~/.cache/huggingface/transformers/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /cardiffnlp/twitter-roberta-base-sentiment/resolve/main/vocab.json HTTP/1.1\" 200 0\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /cardiffnlp/twitter-roberta-base-sentiment/resolve/main/config.json HTTP/1.1\" 200 0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load pre-trained tokenizer and model from Hugging Face\n",
    "model_checkpoint = \"cardiffnlp/twitter-roberta-base-sentiment\"\n",
    "tokenizer = RobertaTokenizer.from_pretrained(model_checkpoint)\n",
    "model = RobertaForSequenceClassification.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5de49f88b742450c854da23762eeb63f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convert Pandas DataFrame to Hugging Face Dataset\n",
    "test_dataset = Dataset.from_pandas(test_df)\n",
    "\n",
    "# Preprocess function for tokenizing text\n",
    "def preprocess_function(examples):\n",
    "    cleaned_texts = [str(text) if text else \"\" for text in examples[\"text\"]]\n",
    "    return tokenizer(cleaned_texts, truncation=True, padding=True, max_length=128)\n",
    "\n",
    "# Tokenize the dataset\n",
    "tokenized_test_dataset = test_dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Get the logits (raw output) from the model\n",
    "def get_predictions(tokenized_dataset):\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for batch in tokenized_dataset:\n",
    "            inputs = {key: torch.tensor(val).unsqueeze(0) for key, val in batch.items() if key in tokenizer.model_input_names}\n",
    "            outputs = model(**inputs)\n",
    "            logits = outputs.logits\n",
    "            predicted_class = torch.argmax(logits, dim=-1).item()\n",
    "            predictions.append(predicted_class)\n",
    "    return predictions\n",
    "\n",
    "predictions = get_predictions(tokenized_test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map 3-class predictions to 2-class labels\n",
    "def map_to_binary(predictions):\n",
    "    binary_predictions = []\n",
    "    for pred in predictions:\n",
    "        if pred == 0:  # negative -> depressed\n",
    "            binary_predictions.append(1)\n",
    "        else:  # neutral/positive -> health\n",
    "            binary_predictions.append(0)\n",
    "    return binary_predictions\n",
    "\n",
    "binary_predictions = map_to_binary(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6072\n"
     ]
    }
   ],
   "source": [
    "# True labels\n",
    "true_labels = test_df['label'].tolist()\n",
    "\n",
    "# Compute accuracy\n",
    "accuracy = accuracy_score(true_labels, binary_predictions)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Output logits vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to 'test_results_with_logits.csv'\n"
     ]
    }
   ],
   "source": [
    "# Get the logits (raw output) from the model along with the text and label\n",
    "def get_predictions_with_logits(tokenized_dataset):\n",
    "    texts = []\n",
    "    labels = []\n",
    "    logits_list = []\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(tokenized_dataset):\n",
    "            # Prepare inputs\n",
    "            inputs = {key: torch.tensor(val).unsqueeze(0) for key, val in batch.items() if key in tokenizer.model_input_names}\n",
    "            \n",
    "            # Get model outputs (logits)\n",
    "            outputs = model(**inputs)\n",
    "            logits = outputs.logits.detach().cpu().numpy().flatten() \n",
    "            \n",
    "            # Store text, label, and logits\n",
    "            texts.append(test_df[\"text\"].iloc[i])\n",
    "            labels.append(test_df[\"label\"].iloc[i])\n",
    "            logits_list.append(logits)\n",
    "    \n",
    "    return texts, labels, logits_list\n",
    "\n",
    "# Get predictions and logits for the test dataset\n",
    "texts, labels, logits_list = get_predictions_with_logits(tokenized_test_dataset)\n",
    "\n",
    "# Create a DataFrame to store text, label, and logits\n",
    "results_df = pd.DataFrame({\n",
    "    'text': texts,\n",
    "    'label': labels,\n",
    "    'logits': logits_list\n",
    "})\n",
    "\n",
    "\n",
    "results_df.to_csv('test_results_with_logits.csv', index=False)\n",
    "print(\"Results saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved\n"
     ]
    }
   ],
   "source": [
    "# Get the logits from the model along with the text and label\n",
    "def get_predictions_with_logits(tokenized_dataset):\n",
    "    texts = []\n",
    "    labels = []\n",
    "    logits_list = []\n",
    "    label_preds = [] \n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(tokenized_dataset):\n",
    "            inputs = {key: torch.tensor(val).unsqueeze(0) for key, val in batch.items() if key in tokenizer.model_input_names}\n",
    "            \n",
    "            outputs = model(**inputs)\n",
    "            logits = outputs.logits.detach().cpu().numpy().flatten() \n",
    "            \n",
    "            # Get the predicted label (index of max logit value)\n",
    "            predicted_label = logits.argmax() \n",
    "            \n",
    "            # Map 3-class predictions to 2-class labels (depressed = 1, health = 0)\n",
    "            label_pred = map_to_binary([predicted_label])[0]\n",
    "            \n",
    "            # Store text, label, logits, and predicted label\n",
    "            texts.append(test_df[\"text\"].iloc[i])\n",
    "            labels.append(test_df[\"label\"].iloc[i])\n",
    "            logits_list.append(logits) \n",
    "            label_preds.append(label_pred)\n",
    "    \n",
    "    return texts, labels, logits_list, label_preds\n",
    "\n",
    "# Get predictions, logits, and predicted labels for the test dataset\n",
    "texts, labels, logits_list, label_preds = get_predictions_with_logits(tokenized_test_dataset)\n",
    "\n",
    "results_df = pd.DataFrame({\n",
    "    'text': texts,\n",
    "    'label': labels,\n",
    "    'logits': logits_list,  \n",
    "    'label_pred': label_preds  \n",
    "})\n",
    "\n",
    "results_df.to_csv('test_results_with_logits_and_predictions.csv', index=False)\n",
    "print(\"Results saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Misclassified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.getLogger(\"transformers\").setLevel(logging.ERROR)\n",
    "logging.getLogger(\"datasets\").setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out misclassified samples\n",
    "misclassified_df = results_df[results_df['label'] != results_df['label_pred']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "misclassified_df.to_csv('misclassified_samples_nonTrain.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassification distribution:\n",
      "label\n",
      "0    179\n",
      "1    125\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Count per label\n",
    "misclassified_counts = misclassified_df['label'].value_counts()\n",
    "\n",
    "# Display distribution\n",
    "print(f\"Misclassification distribution:\\n{misclassified_counts}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "misclassified_df['label_pred'].value_counts().plot(kind='bar', title=\"Misclassified Samples by Predicted Label\")\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 304 entries, 3 to 773\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   text        303 non-null    object\n",
      " 1   label       304 non-null    int64 \n",
      " 2   logits      304 non-null    object\n",
      " 3   label_pred  304 non-null    int64 \n",
      "dtypes: int64(2), object(2)\n",
      "memory usage: 11.9+ KB\n"
     ]
    }
   ],
   "source": [
    "misclassified_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>logits</th>\n",
       "      <th>label_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>late night snack glass oj b c m quot sickness ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[3.0297499, -0.51466477, -2.6291506]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ensconced thought diametrically opposed gradua...</td>\n",
       "      <td>1</td>\n",
       "      <td>[-1.0581923, 1.1503406, -0.1986687]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ve tinnitus like year related anxiety neck pai...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.28424332, 0.87818867, -1.2747302]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>amidst conflict ukraine russia contention test...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.6774169, 1.3289019, -2.1771953]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>nearly dollar saved student working hour week ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[-1.4303167, 0.43625298, 1.0886158]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>really cold</td>\n",
       "      <td>0</td>\n",
       "      <td>[1.0366995, 0.5091419, -1.427758]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>fucking boredom make wan na smoke</td>\n",
       "      <td>0</td>\n",
       "      <td>[2.2685206, -0.13657193, -2.0035968]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>riry pain nomming hand sprayed cat nip mist jo...</td>\n",
       "      <td>0</td>\n",
       "      <td>[1.1416659, 0.70770323, -1.8363186]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>talking bout depression girl just got pill</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.81741226, 1.0070555, -1.911675]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>thanks chaffie thousand apology fogive sinned</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.7478117, 0.4113267, -1.1696522]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  label  \\\n",
       "3   late night snack glass oj b c m quot sickness ...      0   \n",
       "4   ensconced thought diametrically opposed gradua...      1   \n",
       "14  ve tinnitus like year related anxiety neck pai...      1   \n",
       "18  amidst conflict ukraine russia contention test...      1   \n",
       "21  nearly dollar saved student working hour week ...      1   \n",
       "23                                        really cold      0   \n",
       "26                  fucking boredom make wan na smoke      0   \n",
       "27  riry pain nomming hand sprayed cat nip mist jo...      0   \n",
       "28         talking bout depression girl just got pill      1   \n",
       "33      thanks chaffie thousand apology fogive sinned      0   \n",
       "\n",
       "                                  logits  label_pred  \n",
       "3   [3.0297499, -0.51466477, -2.6291506]           1  \n",
       "4    [-1.0581923, 1.1503406, -0.1986687]           0  \n",
       "14  [0.28424332, 0.87818867, -1.2747302]           0  \n",
       "18    [0.6774169, 1.3289019, -2.1771953]           0  \n",
       "21   [-1.4303167, 0.43625298, 1.0886158]           0  \n",
       "23     [1.0366995, 0.5091419, -1.427758]           1  \n",
       "26  [2.2685206, -0.13657193, -2.0035968]           1  \n",
       "27   [1.1416659, 0.70770323, -1.8363186]           1  \n",
       "28    [0.81741226, 1.0070555, -1.911675]           0  \n",
       "33    [0.7478117, 0.4113267, -1.1696522]           1  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "misclassified_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "02e5c984c09f435a8c9ad7fee9c0a3b6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5e5b1574b89f4266bf5069a75bfd1259",
       "IPY_MODEL_6b969a0ec21d44afbb294752e0829879",
       "IPY_MODEL_5e79822663234199bbe63f1bb3b07739"
      ],
      "layout": "IPY_MODEL_27888e6192c74a13b51525f5b069246c"
     }
    },
    "18ef0f43fc8c407db9e93fc2eb456f09": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1d5cf447c04047a5b763e2258918a5a3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1fac47e82d8445fe9c061c5c817b7c07": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "27888e6192c74a13b51525f5b069246c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2f0301ad571c43f4a3f6c74ee11478ae": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4184657ba94e4390a12546a75189b23c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8f0d6b2d68e24d4f92eecdf40266dbb5",
      "placeholder": "",
      "style": "IPY_MODEL_1d5cf447c04047a5b763e2258918a5a3",
      "value": "774/774[00:00&lt;00:00,1778.11examples/s]"
     }
    },
    "43d38d94d64843c2822fcb105c44b9ff": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "49adb58f54964934ab25de27be100fb2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4c8fdd7ab5e5412989b1eebed2cb0f32": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "570858b160114bd7989322f8171be5f5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5e5b1574b89f4266bf5069a75bfd1259": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2f0301ad571c43f4a3f6c74ee11478ae",
      "placeholder": "",
      "style": "IPY_MODEL_920685d2c4524821aa53546cb15ca4cc",
      "value": "Map:100%"
     }
    },
    "5e79822663234199bbe63f1bb3b07739": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1fac47e82d8445fe9c061c5c817b7c07",
      "placeholder": "",
      "style": "IPY_MODEL_8aed4c454d1f4264aaabaa1d9df58012",
      "value": "773/773[00:00&lt;00:00,1801.24examples/s]"
     }
    },
    "689163b20cda4097ace66a99862d6c61": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_947d37a10f674733897f7c062feff1e6",
      "max": 6184,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_799015bd31c8441f9de61f77bd381563",
      "value": 6184
     }
    },
    "6b969a0ec21d44afbb294752e0829879": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_49adb58f54964934ab25de27be100fb2",
      "max": 773,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c248980abfef4874ab0003a5c5fe767d",
      "value": 773
     }
    },
    "6da44f13a284451ca8c4bf68c3d8b421": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f92da9b60b0b495f8b937c9bda1c7f6a",
       "IPY_MODEL_689163b20cda4097ace66a99862d6c61",
       "IPY_MODEL_fabf53cd91ca4a1e89567bf7c6d47c49"
      ],
      "layout": "IPY_MODEL_8d3f09e85c57469fbbe12a566097431b"
     }
    },
    "799015bd31c8441f9de61f77bd381563": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "8266a18427f249d4b25c6ac3ff87f33b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "85fbfe4074c1472ea5d67c9cffabb38c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "87ee335a83a24c3d9df0668f5590f94b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c4679acd51ed487db62902f93b68597d",
       "IPY_MODEL_f38daed0ecee4e5f93f95435feca0992",
       "IPY_MODEL_4184657ba94e4390a12546a75189b23c"
      ],
      "layout": "IPY_MODEL_abd7f1c0737247e48a2862bbbee86b74"
     }
    },
    "8aed4c454d1f4264aaabaa1d9df58012": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8d3f09e85c57469fbbe12a566097431b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8f0d6b2d68e24d4f92eecdf40266dbb5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "920685d2c4524821aa53546cb15ca4cc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "947d37a10f674733897f7c062feff1e6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "abd7f1c0737247e48a2862bbbee86b74": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c248980abfef4874ab0003a5c5fe767d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c4679acd51ed487db62902f93b68597d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d764d603b0704c9890291f2e2db0e76a",
      "placeholder": "",
      "style": "IPY_MODEL_570858b160114bd7989322f8171be5f5",
      "value": "Map:100%"
     }
    },
    "d764d603b0704c9890291f2e2db0e76a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "da47dee2ce5d47c99e5b55d2e61be352": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f38daed0ecee4e5f93f95435feca0992": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_43d38d94d64843c2822fcb105c44b9ff",
      "max": 774,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8266a18427f249d4b25c6ac3ff87f33b",
      "value": 774
     }
    },
    "f92da9b60b0b495f8b937c9bda1c7f6a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_85fbfe4074c1472ea5d67c9cffabb38c",
      "placeholder": "",
      "style": "IPY_MODEL_da47dee2ce5d47c99e5b55d2e61be352",
      "value": "Map:100%"
     }
    },
    "fabf53cd91ca4a1e89567bf7c6d47c49": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4c8fdd7ab5e5412989b1eebed2cb0f32",
      "placeholder": "",
      "style": "IPY_MODEL_18ef0f43fc8c407db9e93fc2eb456f09",
      "value": "6184/6184[00:02&lt;00:00,2540.53examples/s]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
